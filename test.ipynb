{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_INPUT {'name': '_INPUT', 'type': 'args', 'args': (), 'kwargs': {}}\n",
      "start {'type': 'sample', 'name': 'start', 'fn': Uniform(low: 0.0, high: 3.0), 'is_observed': True, 'args': (), 'kwargs': {}, 'value': tensor(0.5000), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None, 'is_cont': False, 'log_prob_sum': tensor(-1.0986)}\n",
      "step_0 {'type': 'sample', 'name': 'step_0', 'fn': Uniform(low: -1.0, high: 1.0), 'is_observed': True, 'args': (), 'kwargs': {}, 'value': tensor(-0.4000), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None, 'is_cont': False, 'log_prob_sum': tensor(-0.6931)}\n",
      "step_1 {'type': 'sample', 'name': 'step_1', 'fn': Uniform(low: -1.0, high: 1.0), 'is_observed': True, 'args': (), 'kwargs': {}, 'value': tensor(-0.9000), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None, 'is_cont': False, 'log_prob_sum': tensor(-0.6931)}\n",
      "obs {'type': 'sample', 'name': 'obs', 'fn': Normal(loc: 1.100000023841858, scale: 0.10000000149011612), 'is_observed': True, 'args': (), 'kwargs': {}, 'value': tensor(1.3000), 'infer': {}, 'scale': 1.0, 'mask': None, 'cond_indep_stack': (), 'done': True, 'stop': False, 'continuation': None, 'is_cont': False, 'log_prob_sum': tensor(-0.6164)}\n",
      "_RETURN {'name': '_RETURN', 'type': 'return', 'value': 0.5}\n",
      "('start', tensor(0.5000))\n",
      "('start', 'step_0', 'step_1')\n",
      "3\n",
      "{'start': tensor(0.5000), 'step_0': tensor(-0.4000), 'step_1': tensor(-0.9000)}\n",
      "-3.1012600899986262\n",
      "tensor(-3.1013)\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyro.poutine as poutine\n",
    "import pyro.distributions as dist\n",
    "\n",
    "pyro.set_rng_seed(101)\n",
    "\n",
    "def walk_model():\n",
    "    import pyro\n",
    "    import torch\n",
    "\n",
    "    start = pyro.sample(\"start\", pyro.distributions.Uniform(0, 3), is_cont=False)\n",
    "    t = 0\n",
    "    position = start\n",
    "    distance = torch.tensor(0.0)\n",
    "    while position > 0 and position < 10:\n",
    "        step = pyro.sample(f\"step_{t}\", pyro.distributions.Uniform(-1, 1), is_cont=False)\n",
    "        distance = distance + torch.abs(step)\n",
    "        position = position + step\n",
    "        t = t + 1\n",
    "    pyro.sample(\"obs\", pyro.distributions.Normal(1.1, 0.1), obs=distance, is_cont=False)\n",
    "    return start.item()\n",
    "\n",
    "def make_log_joint(model):\n",
    "    def _log_joint(cond_data, *args, **kwargs):\n",
    "        conditioned_model = poutine.condition(model, data=cond_data)\n",
    "        trace = poutine.trace(conditioned_model).get_trace(*args, **kwargs)\n",
    "        # print(dict(trace))\n",
    "        return trace.log_prob_sum(), dict(trace.nodes)\n",
    "    return _log_joint\n",
    "scale_log_joint = make_log_joint(walk_model)\n",
    "\n",
    "value, trace = scale_log_joint({\"start\": torch.tensor(0.5), \"step_0\": torch.tensor(-0.9), \"step_1\": torch.tensor(-0.9), \"obs\": torch.tensor(1.3)})\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "for site_name in trace:\n",
    "    print(site_name, trace[site_name])\n",
    "dic = {site_name: trace[site_name]['value'] for site_name in trace if site_name not in [\"_INPUT\", \"_RETURN\", \"obs\"]}\n",
    "print(list(dic.items())[0])\n",
    "print(tuple(dic.keys()))\n",
    "print(len(dic.keys()))\n",
    "print({site_name: trace[site_name]['value'] for site_name in trace if site_name not in [\"_INPUT\", \"_RETURN\", \"obs\"]})\n",
    "\n",
    "print(np.log(norm(1.1, 0.1).pdf(1.3) * 1/2 * 1/2 * 1/3))\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "pyro.sample(\"is_test\", torch.distributions.Laplace(torch.zeros(10), torch.ones(10)).sample)\n",
    "for i in range(3, 10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _potential_fn(self, params):\n",
    "        params_constrained = {k: self.transforms[k].inv(v) for k, v in params.items()}\n",
    "        cond_model = poutine.condition(self.model, params_constrained)\n",
    "        model_trace = poutine.trace(cond_model).get_trace(\n",
    "            *self.model_args, **self.model_kwargs\n",
    "        )\n",
    "        log_joint = self.trace_prob_evaluator.log_prob(model_trace)\n",
    "        for name, t in self.transforms.items():\n",
    "            log_joint = log_joint - torch.sum(\n",
    "                t.log_abs_det_jacobian(params_constrained[name], params[name])\n",
    "            )\n",
    "        return -log_joint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'step_0': tensor(-0.4000), 'step_1': tensor(-0.9000)}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14900/1196041644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'start'"
     ]
    }
   ],
   "source": [
    "print(dic)\n",
    "dic.pop('start')\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isfinite(torch.tensor(14.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c8186fc8f831c0d0284457f5606486ffc43a4beb5dcea2d74f74b3141dd4857d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 ('cs6216': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
